{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display \n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = vis\n",
    "# H = inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/supercomp/MapTransfer/dataset_vis2inf/dataset_pix2pix\"\n",
    "# example\n",
    "Image.open(dataset_path+'/example/20.0_49.0_000.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TRAIN_DIR = dataset_path + '/train'\n",
    "VAL_DIR = dataset_path + '/valid'\n",
    "TEST_DIR = dataset_path + '/test'\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "LAMBDA_IDENTITY = 0.0\n",
    "LAMBDA_CYCLE = 10\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCHS = 10\n",
    "LOAD_MODEL = False\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_gen_inf = \"genh.pth.tar\"\n",
    "CHECKPOINT_GEN_vis= \"genz.pth.tar\"\n",
    "CHECKPOINT_CRITIC_inf= \"critich.pth.tar\"\n",
    "CHECKPOINT_CRITIC_vis= \"criticz.pth.tar\"\n",
    "\n",
    "transform = A.Compose(\n",
    "    [A.Resize(width=256, height=256), ToTensorV2()], additional_targets={\"image0\": \"image\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, torch, os, numpy as np\n",
    "import torch.nn as nn\n",
    "import config\n",
    "import copy\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class MapDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.list_files = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.list_files[index]\n",
    "        img_path = os.path.join(self.root_dir, img_file)\n",
    "        image = np.array(Image.open(img_path))\n",
    "        input_image = image[:, :256, :]\n",
    "        target_image = image[:, 256:, :]\n",
    "\n",
    "        augmentations = transform(image=input_image, image0=target_image)\n",
    "        input_image = augmentations[\"image\"]\n",
    "        target_image = augmentations[\"image0\"]\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = MapDataset(TRAIN_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=5)\n",
    "    for x, y in loader:\n",
    "        print(x.shape)\n",
    "        save_image(x, \"x.png\")\n",
    "        save_image(y, \"y.png\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                features[0],\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n",
    "            in_channels = feature\n",
    "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "def test():\n",
    "    x = torch.randn((5, 3, 256, 256))\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
    "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
    "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
    "            ]\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "        x = self.res_blocks(x)\n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last(x))\n",
    "\n",
    "def test():\n",
    "    img_channels = 3\n",
    "    img_size = 256\n",
    "    x = torch.randn((2, img_channels, img_size, img_size))\n",
    "    gen = Generator(img_channels, 9)\n",
    "    print(gen(x).shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import HorsevisualDataset\n",
    "import sys\n",
    "from utils import save_checkpoint, load_checkpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from discriminator_model import Discriminator\n",
    "from generator_model import Generator\n",
    "\n",
    "def train_fn(disc_inf, disc_vis, gen_vis, gen_inf, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
    "    H_reals = 0\n",
    "    H_fakes = 0\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (visual, horse) in enumerate(loop):\n",
    "        visual = visual.to(config.DEVICE)\n",
    "        horse = horse.to(config.DEVICE)\n",
    "\n",
    "        # Train Discriminators H and Z\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_infrared = gen_inf(visual)\n",
    "            D_inf_real = disc_inf(horse)\n",
    "            D_inf_fake = disc_inf(fake_infrared.detach())\n",
    "            H_reals += D_inf_real.mean().item()\n",
    "            H_fakes += D_inf_fake.mean().item()\n",
    "            D_inf_real_loss = mse(D_inf_real, torch.ones_like(D_inf_real))\n",
    "            D_inf_fake_loss = mse(D_inf_fake, torch.zeros_like(D_inf_fake))\n",
    "            D_inf_loss = D_inf_real_loss + D_inf_fake_loss\n",
    "\n",
    "            fake_visual = gen_vis(horse)\n",
    "            D_vis_real = disc_vis(visual)\n",
    "            D_vis_fake = disc_vis(fake_visual.detach())\n",
    "            D_vis_real_loss = mse(D_vis_real, torch.ones_like(D_vis_real))\n",
    "            D_vis_fake_loss = mse(D_vis_fake, torch.zeros_like(D_vis_fake))\n",
    "            D_vis_loss = D_vis_real_loss + D_vis_fake_loss\n",
    "\n",
    "            # put it togethor\n",
    "            D_loss = (D_inf_loss + D_vis_loss)/2\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        # Train Generators H and Z\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # adversarial loss for both generators\n",
    "            D_inf_fake = disc_inf(fake_infrared)\n",
    "            D_vis_fake = disc_vis(fake_visual)\n",
    "            loss_G_inf= mse(D_inf_fake, torch.ones_like(D_inf_fake))\n",
    "            loss_G_vis= mse(D_vis_fake, torch.ones_like(D_vis_fake))\n",
    "\n",
    "            # cycle loss\n",
    "            cycle_visual = gen_vis(fake_infrared)\n",
    "            cycle_infrared = gen_inf(fake_visual)\n",
    "            cycle_visual_loss = l1(visual, cycle_visual)\n",
    "            cycle_infrared_loss = l1(horse, cycle_infrared)\n",
    "\n",
    "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
    "            identity_visual = gen_vis(visual)\n",
    "            identity_infrared = gen_inf(horse)\n",
    "            identity_visual_loss = l1(visual, identity_visual)\n",
    "            identity_infrared_loss = l1(horse, identity_infrared)\n",
    "\n",
    "            # add all togethor\n",
    "            G_loss = (\n",
    "                loss_G_vis\n",
    "                + loss_G_inf\n",
    "                + cycle_visual_loss * config.LAMBDA_CYCLE\n",
    "                + cycle_infrared_loss * config.LAMBDA_CYCLE\n",
    "                + identity_infrared_loss * config.LAMBDA_IDENTITY\n",
    "                + identity_visual_loss * config.LAMBDA_IDENTITY\n",
    "            )\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            save_image(fake_infrared*0.5+0.5, f\"saved_images/horse_{idx}.png\")\n",
    "            save_image(fake_visual*0.5+0.5, f\"saved_images/visual_{idx}.png\")\n",
    "\n",
    "        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    disc_inf = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    disc_vis = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    gen_vis = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)\n",
    "    gen_inf = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)\n",
    "    opt_disc = optim.Adam(\n",
    "        list(disc_inf.parameters()) + list(disc_vis.parameters()),\n",
    "        lr=config.LEARNING_RATE,\n",
    "        betas=(0.5, 0.999),\n",
    "    )\n",
    "\n",
    "    opt_gen = optim.Adam(\n",
    "        list(gen_vis.parameters()) + list(gen_inf.parameters()),\n",
    "        lr=config.LEARNING_RATE,\n",
    "        betas=(0.5, 0.999),\n",
    "    )\n",
    "\n",
    "    L1 = nn.L1Loss()\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_gen_inf, gen_inf, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN_vis, gen_vis, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_CRITIC_inf, disc_inf, opt_disc, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_CRITIC_vis, disc_vis, opt_disc, config.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    dataset = HorsevisualDataset(\n",
    "        root_infrared=config.TRAIN_DIR+\"/horses\", root_visual=config.TRAIN_DIR+\"/visuals\", transform=config.transforms\n",
    "    )\n",
    "    val_dataset = HorsevisualDataset(\n",
    "       root_infrared=\"cyclegan_test/horse1\", root_visual=\"cyclegan_test/visual1\", transform=config.transforms\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    g_scaler = torch.cuda.amp.GradScaler()\n",
    "    d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train_fn(disc_inf, disc_vis, gen_vis, gen_inf, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
    "\n",
    "        if config.SAVE_MODEL:\n",
    "            save_checkpoint(gen_inf, opt_gen, filename=config.CHECKPOINT_gen_inf)\n",
    "            save_checkpoint(gen_vis, opt_gen, filename=config.CHECKPOINT_GEN_vis)\n",
    "            save_checkpoint(disc_inf, opt_disc, filename=config.CHECKPOINT_CRITIC_inf)\n",
    "            save_checkpoint(disc_vis, opt_disc, filename=config.CHECKPOINT_CRITIC_vis)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b01c1b37dc2cdb5667c43565e2ff6fad3fcfcda2b7ec5489071cd55dee2e1491"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('mis-information-zones')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
